<script>
	import AsideBox from "../AsideBox.svelte";
</script>

<AsideBox>
	<h2 slot="title">Assisted decoding & Search</h2>

	<p>
		As I see it, "search" in the context of model architecture means structuring
		a problem in such a way that the model can spend more compute and/or access
		more data for each inference action. This could mean a variety of things,
		perhaps the model is allowed to look at similar training data instances. Or,
		the model might be evaluated many times in a sort of search tree.
	</p>

	Search can do a lot
	<br />
	* Using retrieval to enhance retrieval vectors:
	<a href="https://arxiv.org/abs//2306.07196"
		>Retrieval-Enhanced Contrastive Vision-Text Models</a
	>, makes CLIP perform much better at retrieval by training a small adapter
	that gets to look at similar cross modal examples for a query
	<br />
	* Using assistant algorithms to find solutions:
	<a href="https://www.nature.com/articles/s41586-023-06747-5">
		Solving olympiad geometry without human demonstrations</a
	>, where an LLM works in synergy with a symbolic deduction engine
	<br />
	* Solutions in the output space of energy models:
	<a href="https://arxiv.org/abs/2109.00137">Implicit behavioral cloning</a>,
	where policy actions are generated by sampling (searching) from a
	distribution. The distribution is what is produced by the actual model
	<br />
	* Retrieving real data to improve the realism of fake data:
	<a
		href="https://cfg.mit.edu/assets/images/cg2real-improving-the-realism-of-computer-generated-images-using-a-collection-of-photographs.pdf"
		>CG2Real</a
	>
	Really fun older paper about image retrieval to make computer graphics highly
	realistic
	<br />
	* Requiring less memorization of model parameters:
	<a href="https://arxiv.org/abs/2112.04426"
		>Improving language models by retrieving from trillions of tokens</a
	>
	<br />
</AsideBox>
